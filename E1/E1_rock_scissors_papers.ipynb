{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "juvenile-boundary",
   "metadata": {},
   "source": [
    "# Exploration 1. 가위바위보 분류기 만들기\n",
    "\n",
    "- 첫번째 exploration 가위바위보 분류기를 jupyter notebook으로 구현했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-appliance",
   "metadata": {},
   "source": [
    "## 1) 가위바위보 이미지 데이터를 가져와서 사이즈를 28 * 28로 변경하기\n",
    "\n",
    "- Python Image Library, tensorflow, numpy, matplotlib 를 활용했습니다.\n",
    "- 이미지 사이즈를 28 * 28 로 조정하는 함수를 정의했습니다. (resize_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "toxic-valuation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527  images to be resized.\n",
      "1527  images resized.\n",
      "1532  images to be resized.\n",
      "1532  images resized.\n",
      "1527  images to be resized.\n",
      "1527  images resized.\n",
      "가위, 바위, 보 train 이미지 resize 완료!\n",
      "\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위, 바위, 보 test 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 이미지를 재조정하는 함수를 정의합니다.\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "\n",
    "    \n",
    "# 가위, 바위, 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서 사이즈 변경\n",
    "scissor_path = os.getenv(\"HOME\") + \"/aiffel/etc/rock_scissor_paper/scissor\"\n",
    "resize_images(scissor_path)\n",
    "rock_path = os.getenv(\"HOME\") + \"/aiffel/etc/rock_scissor_paper/rock\"\n",
    "resize_images(rock_path)\n",
    "paper_path = os.getenv(\"HOME\") + \"/aiffel/etc/rock_scissor_paper/paper\"\n",
    "resize_images(paper_path)\n",
    "\n",
    "print(\"가위, 바위, 보 train 이미지 resize 완료!\\n\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/etc/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/etc/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/etc/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위, 바위, 보 test 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-pathology",
   "metadata": {},
   "source": [
    "## 2) 가위바위보 train 데이터를 변수에 저장\n",
    "\n",
    "- load_data 함수를 정의해서 train data 4586개를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "nervous-township",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 4586 입니다.\n",
      "x_train shape: (4586, 28, 28, 3)\n",
      "y_train shape: (4586,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path, number_of_data=4586): \n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/etc/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "informative-cinema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train data의 0번째 인덱스 확인\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-twelve",
   "metadata": {},
   "source": [
    "## 3) 딥러닝 네트워크 설계 및 학습\n",
    "- tensorflow keras의 Sequential 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "incredible-header",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 224,707\n",
      "Trainable params: 224,707\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝 네트워크 설계하기\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,3))) # input_shape에는 이미지 사이즈에 맞는 값을 넣어줘야 합니다.\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax')) # 마지막 Dense 레이어에는 클래스 개수인 3을 넣어줘야 합니다.\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "streaming-anime",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "144/144 [==============================] - 5s 14ms/step - loss: 1.0629 - accuracy: 0.4169\n",
      "Epoch 2/10\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7835\n",
      "Epoch 3/10\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2585 - accuracy: 0.9114\n",
      "Epoch 4/10\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1352 - accuracy: 0.9579\n",
      "Epoch 5/10\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.0753 - accuracy: 0.9757\n",
      "Epoch 6/10\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9759\n",
      "Epoch 7/10\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.9970\n",
      "Epoch 8/10\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9995\n",
      "Epoch 9/10\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.0883 - accuracy: 0.9683\n",
      "Epoch 10/10\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.9921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4e6c569250>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "#모델을 학습(훈련)합니다.\n",
    "model.fit(x_train_norm, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-reconstruction",
   "metadata": {},
   "source": [
    "## 4) 테스트 데이터 예측해보기\n",
    "- 훈련한 모델로 테스트 데이터를 예측해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "biological-mayor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트용 데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터를 불러오는 함수를 정의합니다.\n",
    "def load_test_data(img_path, number_of_data=300):  \n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트용 데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/etc/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_test_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_test.shape))\n",
    "print(\"y_train shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "egyptian-meaning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 1s - loss: 0.3661 - accuracy: 0.8567\n",
      "test_loss: 0.36608797311782837 \n",
      "test_accuracy: 0.8566666841506958\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-given",
   "metadata": {},
   "source": [
    "## 5) 회고\n",
    "- 제가 직접 찍은 가위바위보 이미지 300장을 훈련하고, 다른 사람의 데이터를 받아서 테스트했을 때에는 accuracy가 낮게 나왔습니다.\n",
    "- 이를 개선하고자 AIFFEL 양재캠 노션 페이지에서 다른 사람들의 데이터를 가져와서 4586장을 훈련시켰고, 훈련 데이터셋에는 포함되지 않은 사람의 가위바위보 이미지 데이터 300장을 가져와서 테스트했습니다. 훈련했을 때의 정확도는 약 99%였지만, 테스트 정확도는 약 85%로 낮아졌습니다. 새로운 데이터를 예측하는 정확도가 낮아지긴 했지만, 어느 정도는 잘 맞추고\n",
    "- 정리: 데이터의 양과 질이 중요하다는 것을 느꼈습니다. 편향된 데이터를 학습하면 새로운 데이터를 예측하기 힘듭니다. 따라서 다양한 데이터 셋을 많이 학습하는 것이 좋습니다. 그리고 이미지 데이터의 경우 화질이나 주변 배경(noise)에 따라 품질이 저하될 수 있습니다. 품질이 저하된 데이터를 학습하는 것은 도움이 되지 않습니다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
